{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#import logging\n",
    "\n",
    "#import string\n",
    "from nltk.tokenize import RegexpTokenizer # tokenizing\n",
    "from nltk.corpus import stopwords  # list of stop words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer # lemmatizer\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model\n",
    "\n",
    "Choose one option from below.  The first 2 are the same model, which can be used to calculate a probability score for a phrase. The first is just the word vectors (no hidden layer weights). The second is the full model (can calculate score).\n",
    "\n",
    "The last file is the negative sampling model, which always for the 'predict_output_word' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full model with softmax, CBOW, and no negative sampling\n",
    "path = \"/Users/stevenfelix/Documents/DataScience_local/Insight/Demo_App/flaskexample/models/\"\n",
    "file = 'model_full_50M_sg0_sz250_win5_min3_hs1_neg0'\n",
    "model= gensim.models.word2vec.Word2Vec.load(path+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**text preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = re.compile(r\"'|-|\\\"\")\n",
    "# all non alphanumeric\n",
    "symbols = re.compile(r'(\\W+)', re.U)\n",
    "# single character removal\n",
    "singles = re.compile(r'(\\s\\S\\s)', re.I|re.U)\n",
    "# separators (any whitespace)\n",
    "seps = re.compile(r'\\s+')\n",
    "# tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # tokens separated by white spice\n",
    "# stop words\n",
    "stops = set(stopwords.words('english')) # list of english stop words\n",
    "\n",
    "# cleaner (order matters)\n",
    "def clean(text, rmv_stop_words=True, return_tokens=False): \n",
    "    text = text.lower()\n",
    "    text = contractions.sub('', text)\n",
    "    text = symbols.sub(r' \\1 ', text)\n",
    "    text = singles.sub(' ', text)\n",
    "    text = seps.sub(' ', text)\n",
    "    tokens = tokenizer.tokenize(text)     # tokenize\n",
    "    if rmv_stop_words:\n",
    "        tokens = [i for i in tokens if not i in stops] # remove stop words\n",
    "        text = ' '.join(tokens)\n",
    "    if return_tokens:\n",
    "        return tokens\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generating and ranking alternatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" These generate alternative queries and score them and filter them \"\"\"\n",
    "\n",
    "def generate_alternatives(query, n, model, rmv_stop_words=True, return_tokens=True, tags=[]):\n",
    "    try:\n",
    "        syns = get_similar(query, model, rmv_stop_words=rmv_stop_words, return_tokens=return_tokens, tags=tags) # synonyms\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    combs = get_combinations(syns) # combinations\n",
    "    probs = [model.score([sug])[0] for sug in combs] # probabilities\n",
    "    preds_probs =[(p,q) for p,q in zip(probs,combs)] # combine with queries\n",
    "    q_score = model.score([tokenizer.tokenize(query)])[0] # score for original query\n",
    "    preds_probs.sort(reverse=True)\n",
    "    sugs =  [q for p,q in preds_probs[0:n]]\n",
    "    return [' '.join(title) for title in sugs],syns\n",
    "\n",
    "def get_similar(query, model, rmv_stop_words, return_tokens, tags, threshold=.55):\n",
    "    q = clean(query, rmv_stop_words=rmv_stop_words, return_tokens=return_tokens)\n",
    "    # turn each word  of query into its own list\n",
    "    d = [[x] for x in q]\n",
    "    for x in d:\n",
    "        # for each word in original query, add topn similar words to list\n",
    "        # TO DO: catch exceptions\n",
    "        if x[0] not in tags:\n",
    "            x.extend([syn for syn,score in model.most_similar(x[0]) if score > threshold])        \n",
    "    return d\n",
    "\n",
    "def get_combinations(l):\n",
    "    combs = [x for x in product(*l)]\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions,synonyms = generate_alternatives('create column pandas dataframe', 5, model, rmv_stop_words=True, return_tokens=True, tags=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add column pandas dataframe',\n",
       " 'create columns pandas dataframe',\n",
       " 'adding columns pandas dataframe',\n",
       " 'adding column pandas dataframe',\n",
       " 'add columns pandas dataframe']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['create',\n",
       "  'creating',\n",
       "  'add',\n",
       "  'generate',\n",
       "  'creat',\n",
       "  'creation',\n",
       "  'construct',\n",
       "  'adding',\n",
       "  'creates',\n",
       "  'generating',\n",
       "  'created'],\n",
       " ['column',\n",
       "  'columns',\n",
       "  'row',\n",
       "  'colum',\n",
       "  'table',\n",
       "  'colums',\n",
       "  'coloumn',\n",
       "  'rows',\n",
       "  'cell',\n",
       "  'field'],\n",
       " ['pandas', 'multiindexed'],\n",
       " ['dataframe',\n",
       "  'dataframes',\n",
       "  'multiindexing',\n",
       "  'datetimeindex',\n",
       "  'df',\n",
       "  'read_csv',\n",
       "  'pivot_table',\n",
       "  'rolling_mean',\n",
       "  'asfreq',\n",
       "  'value_counts']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
