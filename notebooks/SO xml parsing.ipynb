{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice extracting text with small text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = etree.parse(\"/Volumes/Bernie the Backup/comments_test.xml\")\n",
    "root = f.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for el in root.getchildren():\n",
    "    l.append(el.attrib['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using huge file: Serially extract 'Text' from each row/dictionary and write to file?\n",
    "\n",
    "http://boscoh.com/programming/reading-xml-serially.html\n",
    "\n",
    "https://www.ibm.com/developerworks/library/x-hiperfparse/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serially reading xml and writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serially_parse_xml(source, destination, attributes, start=0, stop=100000):\n",
    "    if isinstance(attributes, str):\n",
    "        attributes = [attributes]\n",
    "    context = etree.iterparse(source)\n",
    "    i=start\n",
    "    for _, elem in context:\n",
    "        i+=1\n",
    "        if i <= start:\n",
    "            continue\n",
    "        for attribute in attributes:\n",
    "            try: \n",
    "                destination.write(elem.attrib[attribute]+'\\n')\n",
    "            except KeyError:\n",
    "                continue\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]  # clean up preceding siblings\n",
    "        if i%1000000==0:\n",
    "            print(\"{} posts parsed\".format(i))\n",
    "        if stop and i >= stop:\n",
    "            break\n",
    "    print(\"Parsing completed at {}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/Bernie the Backup/\"\n",
    "with open(path+'comments2.txt','w') as dest:\n",
    "    serially_parse_xml(path+'Comments.xml', dest, 'Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 posts parsed\n",
      "2000000 posts parsed\n",
      "3000000 posts parsed\n",
      "4000000 posts parsed\n",
      "5000000 posts parsed\n",
      "6000000 posts parsed\n",
      "7000000 posts parsed\n",
      "8000000 posts parsed\n",
      "9000000 posts parsed\n",
      "10000000 posts parsed\n",
      "11000000 posts parsed\n",
      "12000000 posts parsed\n",
      "13000000 posts parsed\n",
      "14000000 posts parsed\n",
      "15000000 posts parsed\n",
      "16000000 posts parsed\n",
      "17000000 posts parsed\n",
      "18000000 posts parsed\n",
      "19000000 posts parsed\n",
      "20000000 posts parsed\n",
      "21000000 posts parsed\n",
      "22000000 posts parsed\n",
      "23000000 posts parsed\n",
      "24000000 posts parsed\n",
      "25000000 posts parsed\n",
      "26000000 posts parsed\n",
      "27000000 posts parsed\n",
      "28000000 posts parsed\n",
      "29000000 posts parsed\n",
      "30000000 posts parsed\n",
      "31000000 posts parsed\n",
      "32000000 posts parsed\n",
      "33000000 posts parsed\n",
      "34000000 posts parsed\n"
     ]
    }
   ],
   "source": [
    "path = \"/Volumes/Bernie the Backup/\"\n",
    "with open(path+'posts.txt','w') as dest:\n",
    "    serially_parse_xml(path+'Posts.xml', dest, ['Title','Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making smaller posts file...just title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51000000 posts parsed\n",
      "52000000 posts parsed\n",
      "53000000 posts parsed\n",
      "54000000 posts parsed\n",
      "55000000 posts parsed\n",
      "56000000 posts parsed\n",
      "57000000 posts parsed\n",
      "58000000 posts parsed\n",
      "59000000 posts parsed\n",
      "60000000 posts parsed\n",
      "61000000 posts parsed\n",
      "62000000 posts parsed\n",
      "63000000 posts parsed\n",
      "64000000 posts parsed\n",
      "65000000 posts parsed\n",
      "66000000 posts parsed\n",
      "67000000 posts parsed\n",
      "68000000 posts parsed\n",
      "69000000 posts parsed\n",
      "70000000 posts parsed\n",
      "71000000 posts parsed\n",
      "72000000 posts parsed\n",
      "73000000 posts parsed\n",
      "74000000 posts parsed\n",
      "75000000 posts parsed\n",
      "Parsing completed at 75000000\n"
     ]
    }
   ],
   "source": [
    "# stopping 75,000,000 parsed titles\n",
    "#path = \"/Volumes/Bernie the Backup/\"\n",
    "srcpath = '/Volumes/Bernie the Backup/'\n",
    "destpath = '/Users/stevenfelix/Documents/DataScience_local/Insight/'\n",
    "with open(destpath+'posts_titles_50M.txt','a') as dest:\n",
    "    serially_parse_xml(srcpath+'Posts.xml', dest, ['Title'], start=50000000, stop=75000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
